{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, time, datetime, sys, shutil, stat, torch\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from util.MF_dataset import MF_dataset\n",
    "from util.util import compute_results, visualize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import savemat\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from util.augmentation import RandomFlip, RandomCrop, RandomCropOut, RandomBrightness, RandomNoise\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import ResNet152_Weights, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.attetion = nn.Sequential(\n",
    "            nn.Conv2d(channels * 2, channels // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 2, 2, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.rgb_confidence = nn.Parameter(torch.tensor(1.0))\n",
    "        self.thermal_confidence = nn.Parameter(torch.tensor(1.0))  # 权重更新动量系数\n",
    "\n",
    "    def update(self, rgb_purity, thermal_purity):\n",
    "        self.rgb_prior = self.momentum * self.rgb_prior + (1-self.momentum)* rgb_purity\n",
    "        self.thermal_prior = self.momentum * self.thermal_prior + (1-self.momentum) * thermal_purity\n",
    "        self.rgb_prior.data.clamp_(0.1, 1.0)\n",
    "        self.thermal_prior.data.clamp_(0.1, 1.0)\n",
    "\n",
    "    def forward(self, rgb_feat, thermal_feat):\n",
    "        combined = torch.cat([rgb_feat, thermal_feat], dim=1)\n",
    "        attention_weights = self.attention(combined)  # [B,2,H,W]\n",
    "\n",
    "        # 将置信度参数转换为与attention_weights相同的维度\n",
    "        rgb_conf = torch.sigmoid(self.rgb_confidence).view(1,1,1,1)  # [1,1,1,1]\n",
    "        thermal_conf = torch.sigmoid(self.thermal_confidence).view(1,1,1,1)\n",
    "\n",
    "        # 动态调整权重（关键修改点）\n",
    "        adjusted_weights = torch.cat([\n",
    "            attention_weights[:,0:1] * rgb_conf * self.rgb_prior,\n",
    "            attention_weights[:,1:2] * thermal_conf * self.thermal_prior\n",
    "        ], dim=1)\n",
    "\n",
    "        # 重新归一化\n",
    "        norm_weights = adjusted_weights / (adjusted_weights.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        return rgb_feat * norm_weights[:,0:1] + thermal_feat * norm_weights[:,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息瓶颈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransBottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, upsample=None):\n",
    "        super(TransBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        if upsample is not None and stride != 1:\n",
    "            self.conv3 = nn.ConvTranspose2d(planes, planes, kernel_size=2, stride=stride, padding=0, bias=False)\n",
    "        else:\n",
    "            self.conv3 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.upsample = upsample\n",
    "        self.stride = stride\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):  # 残差连接\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            residual = self.upsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTFNet(nn.Module):\n",
    "    # 初始化\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        self.num_resnet_layers = 152\n",
    "\n",
    "        if self.num_resnet_layers == 50:\n",
    "            resnet_raw_model1 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            resnet_raw_model2 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            self.inplanes = 2048\n",
    "        elif self.num_resnet_layers == 152:\n",
    "            resnet_raw_model1 = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "            resnet_raw_model2 = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "            self.inplanes = 2048\n",
    "\n",
    "        # 基础层\n",
    "        self.encoder_thermal_bn1 = resnet_raw_model1.bn1\n",
    "        self.encoder_thermal_relu = resnet_raw_model1.relu\n",
    "        self.encoder_thermal_pool = resnet_raw_model1.maxpool\n",
    "        self.encoder_rgb_bn1 = resnet_raw_model2.bn1\n",
    "        self.encoder_rgb_relu = resnet_raw_model2.relu\n",
    "        self.encoder_rgb_pool = resnet_raw_model2.maxpool\n",
    "        # 编码器\n",
    "        # Thermal & RGB 第一层\n",
    "        self.encoder_thermal_conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.encoder_thermal_conv1.weight.data = torch.unsqueeze(torch.mean(resnet_raw_model1.conv1.weight.data, dim=1), dim=1)\n",
    "        self.encoder_rgb_conv1 = resnet_raw_model2.conv1\n",
    "        # Thermal & RGB 第二层\n",
    "        self.encoder_thermal_layer1 = resnet_raw_model1.layer1\n",
    "        self.encoder_rgb_layer1 = resnet_raw_model2.layer1\n",
    "        # Thermal & RGB 第三层\n",
    "        self.encoder_thermal_layer2 = resnet_raw_model1.layer2\n",
    "        self.encoder_rgb_layer2 = resnet_raw_model2.layer2\n",
    "        # Thermal & RGB 第四层\n",
    "        self.encoder_thermal_layer3 = resnet_raw_model1.layer3\n",
    "        self.encoder_rgb_layer3 = resnet_raw_model2.layer3\n",
    "        # Thermal & RGB 第五层\n",
    "        self.encoder_thermal_layer4 = resnet_raw_model1.layer4\n",
    "        self.encoder_rgb_layer4 = resnet_raw_model2.layer4\n",
    "        # 权重存储\n",
    "        self.a = nn.Parameter(torch.tensor(1.0))\n",
    "        self.register_buffer('a_history', torch.zeros(100))\n",
    "        self.register_buffer('history_idx', torch.tensor(0))\n",
    "\n",
    "        # 融合层 通道数待定\n",
    "        # self.fusion = AttentionFusion()\n",
    "\n",
    "        # 解码器\n",
    "        self.deconv1 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv2 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv3 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv4 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv5 = self._make_transpose_layer(TransBottleneck, n_class, 2, stride=2)    \n",
    "\n",
    "    def _make_transpose_layer(self, block, planes, blocks, stride=1):\n",
    "        upsample = None\n",
    "        if stride != 1:\n",
    "            upsample = nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.inplanes, planes, kernel_size=2, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        elif self.inplanes != planes:\n",
    "            upsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        for m in upsample.modules():  \n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        layers = []\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, self.inplanes))\n",
    "        layers.append(block(self.inplanes, planes, stride, upsample))\n",
    "        self.inplanes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"强制子类实现forward方法\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion(RTFNet):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__(n_class)\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        rgb = input[:, :3]\n",
    "        thermal = input[:, 3:]\n",
    "\n",
    "        rgb = self.encoder_rgb_conv1(rgb) # (240, 320)\n",
    "        rgb = self.encoder_rgb_bn1(rgb) # (240, 320)\n",
    "        rgb = self.encoder_rgb_relu(rgb) # (240, 320)\n",
    "\n",
    "        thermal = self.encoder_thermal_conv1(thermal) # (240, 320)\n",
    "        thermal = self.encoder_thermal_bn1(thermal) # (240, 320)\n",
    "        thermal = self.encoder_thermal_relu(thermal) # (240, 320)\n",
    "    \n",
    "        fuse = rgb + thermal  # 融合一次\n",
    "\n",
    "        rgb = self.encoder_rgb_pool(rgb) # (120, 160)\n",
    "        thermal = self.encoder_thermal_pool(thermal) # (120, 160)\n",
    "\n",
    "        rgb = self.encoder_rgb_layer1(rgb) # (120, 160)\n",
    "        thermal = self.encoder_thermal_layer1(thermal) # (120, 160)\n",
    "\n",
    "        rgb = rgb + thermal\n",
    "\n",
    "        rgb = self.encoder_rgb_layer2(rgb) # (60, 80)\n",
    "        thermal = self.encoder_thermal_layer2(thermal) # (60, 80)\n",
    "\n",
    "        rgb = rgb + thermal\n",
    "\n",
    "        rgb = self.encoder_rgb_layer3(rgb) # (30, 40)\n",
    "        thermal = self.encoder_thermal_layer3(thermal) # (30, 40)\n",
    "\n",
    "        rgb = rgb + thermal\n",
    "\n",
    "        rgb = self.encoder_rgb_layer4(rgb) # (15, 20)\n",
    "        thermal = self.encoder_thermal_layer4(thermal) # (15, 20)\n",
    "\n",
    "        a = torch.sigmoid(self.a) * 2\n",
    "        fuse = a * rgb + (2 - a) * thermal\n",
    "        self._update_a_history(a.detach())\n",
    "\n",
    "        fuse = self.deconv1(fuse) # (30, 40)\n",
    "        fuse = self.deconv2(fuse) # (60, 80)\n",
    "        fuse = self.deconv3(fuse) # (120, 160)\n",
    "        fuse = self.deconv4(fuse) # (240, 320)\n",
    "        fuse = self.deconv5(fuse) # (480, 640)\n",
    "\n",
    "        return fuse\n",
    "\n",
    "    def _update_a_history(self, a_value):\n",
    "        idx = self.history_idx.item()\n",
    "        self.a_history[idx] = a_value\n",
    "        self.history_idx.fill_((idx + 1) % 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accomplished！\n"
     ]
    }
   ],
   "source": [
    "def unit_test():\n",
    "    num_minibatch = 1\n",
    "    rgb = torch.randn(num_minibatch, 3, 480, 640)\n",
    "    thermal = torch.randn(num_minibatch, 1, 480, 640)\n",
    "    rtf_net = RTFNet(9)\n",
    "    input = torch.cat((rgb, thermal), dim=1)\n",
    "    rtf_net(input)\n",
    "    # print('The model: ', rtf_net.modules)\n",
    "    print('Accomplished！')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unit_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='Train with pytorch')\n",
    "# parser.add_argument('--model_name', '-m', type=str, default='RTFNet')\n",
    "# parser.add_argument('--batch_size', '-b', type=int, default=2)\n",
    "# parser.add_argument('--lr_start', '-ls', type=float, default=0.01)\n",
    "# parser.add_argument('--gpu', '-g', type=int, default=0)\n",
    "# parser.add_argument('--lr_decay', '-ld', type=float, default=0.95)\n",
    "# parser.add_argument('--epoch_max', '-em', type=int, default=1)\n",
    "# parser.add_argument('--epoch_from', '-ef', type=int, default=0)\n",
    "# parser.add_argument('--num_workers', '-j', type=int, default=2)\n",
    "# parser.add_argument('--n_class', '-nc', type=int, default=9)\n",
    "# parser.add_argument('--data_dir', '-dr', type=str, default='./dataset/')\n",
    "# args, unknown = parser.parse_known_args()\n",
    "\n",
    "# augmentation_methods = [\n",
    "#     RandomFlip(prob=0.5),\n",
    "#     RandomCrop(crop_rate=0.1, prob=1.0),\n",
    "#     # RandomCropOut(crop_rate=0.2, prob=1.0),\n",
    "#     # RandomBrightness(bright_range=0.15, prob=0.9),\n",
    "#     # RandomNoise(noise_range=5, prob=0.9),\n",
    "# ]\n",
    "# writer = SummaryWriter()\n",
    "# def train(epo, model, train_loader, optimizer):\n",
    "#     model.train()\n",
    "#     for it, (images, labels, names) in enumerate(train_loader):\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         images = Variable(images).to(device)\n",
    "#         labels = Variable(labels).to(device)\n",
    "#         start_t = time.time() # time.time() returns the current time\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(images)\n",
    "#         loss = F.cross_entropy(logits, labels)  # Note that the cross_entropy function has already include the softmax function\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         lr_this_epo=0\n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             lr_this_epo = param_group['lr']\n",
    "#         print('Train: %s, epo %s/%s, iter %s/%s, lr %.8f, %.2f img/sec, loss %.4f, time %s' \\\n",
    "#             % (args.model_name, epo, args.epoch_max, it+1, len(train_loader), lr_this_epo, len(names)/(time.time()-start_t), float(loss),\n",
    "#               datetime.datetime.now().replace(microsecond=0)-start_datetime))\n",
    "#         if accIter['train'] % 1 == 0:\n",
    "#             writer.add_scalar('Train/loss', loss, accIter['train'])\n",
    "#         view_figure = True # note that I have not colorized the GT and predictions here\n",
    "#         if accIter['train'] % 500 == 0:\n",
    "#             if view_figure:\n",
    "#                 input_rgb_images = vutils.make_grid(images[:,:3], nrow=8, padding=10) # can only display 3-channel images, so images[:,:3]\n",
    "#                 writer.add_image('Train/input_rgb_images', input_rgb_images, accIter['train'])\n",
    "#                 scale = max(1, 255//args.n_class) # label (0,1,2..) is invisable, multiply a constant for visualization\n",
    "#                 groundtruth_tensor = labels.unsqueeze(1) * scale  # mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                 groundtruth_tensor = torch.cat((groundtruth_tensor, groundtruth_tensor, groundtruth_tensor), 1)  # change to 3-channel for visualization\n",
    "#                 groudtruth_images = vutils.make_grid(groundtruth_tensor, nrow=8, padding=10)\n",
    "#                 writer.add_image('Train/groudtruth_images', groudtruth_images, accIter['train'])\n",
    "#                 predicted_tensor = logits.argmax(1).unsqueeze(1) * scale # mini_batch*args.n_class*480*640 -> mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                 predicted_tensor = torch.cat((predicted_tensor, predicted_tensor, predicted_tensor),1) # change to 3-channel for visualization, mini_batch*1*480*640\n",
    "#                 predicted_images = vutils.make_grid(predicted_tensor, nrow=8, padding=10)\n",
    "#                 writer.add_image('Train/predicted_images', predicted_images, accIter['train'])\n",
    "#         accIter['train'] = accIter['train'] + 1\n",
    "\n",
    "\n",
    "# def validation(epo, model, val_loader):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for it, (images, labels, names) in enumerate(val_loader):\n",
    "#             device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#             images = Variable(images).to(device)\n",
    "#             labels = Variable(labels).to(device)\n",
    "#             start_t = time.time() # time.time() returns the current time\n",
    "#             logits = model(images)\n",
    "#             loss = F.cross_entropy(logits, labels)  # Note that the cross_entropy function has already include the softmax function\n",
    "#             print('Val: %s, epo %s/%s, iter %s/%s, %.2f img/sec, loss %.4f, time %s' \\\n",
    "#                   % (args.model_name, epo, args.epoch_max, it + 1, len(val_loader), len(names)/(time.time()-start_t), float(loss),\n",
    "#                     datetime.datetime.now().replace(microsecond=0)-start_datetime))\n",
    "#             if accIter['val'] % 1 == 0:\n",
    "#                 writer.add_scalar('Validation/loss', loss, accIter['val'])\n",
    "#             view_figure = False  # note that I have not colorized the GT and predictions here\n",
    "#             if accIter['val'] % 100 == 0:\n",
    "#                 if view_figure:\n",
    "#                     input_rgb_images = vutils.make_grid(images[:, :3], nrow=8, padding=10)  # can only display 3-channel images, so images[:,:3]\n",
    "#                     writer.add_image('Validation/input_rgb_images', input_rgb_images, accIter['val'])\n",
    "#                     scale = max(1, 255 // args.n_class)  # label (0,1,2..) is invisable, multiply a constant for visualization\n",
    "#                     groundtruth_tensor = labels.unsqueeze(1) * scale  # mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                     groundtruth_tensor = torch.cat((groundtruth_tensor, groundtruth_tensor, groundtruth_tensor), 1)  # change to 3-channel for visualization\n",
    "#                     groudtruth_images = vutils.make_grid(groundtruth_tensor, nrow=8, padding=10)\n",
    "#                     writer.add_image('Validation/groudtruth_images', groudtruth_images, accIter['val'])\n",
    "#                     predicted_tensor = logits.argmax(1).unsqueeze(1)*scale  # mini_batch*args.n_class*480*640 -> mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                     predicted_tensor = torch.cat((predicted_tensor, predicted_tensor, predicted_tensor), 1)  # change to 3-channel for visualization, mini_batch*1*480*640\n",
    "#                     predicted_images = vutils.make_grid(predicted_tensor, nrow=8, padding=10)\n",
    "#                     writer.add_image('Validation/predicted_images', predicted_images, accIter['val'])\n",
    "#             accIter['val'] += 1\n",
    "\n",
    "# def testing(epo, model, test_loader):\n",
    "#     model.eval()\n",
    "#     conf_total = np.zeros((args.n_class, args.n_class))\n",
    "#     label_list = [\"unlabeled\", \"car\", \"person\", \"bike\", \"curve\", \"car_stop\", \"guardrail\", \"color_cone\", \"bump\"]\n",
    "#     testing_results_file = os.path.join(weight_dir, 'testing_results_file.txt')\n",
    "#     with torch.no_grad():\n",
    "#         for it, (images, labels, names) in enumerate(test_loader):\n",
    "#             device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#             images = Variable(images).to(device)\n",
    "#             labels = Variable(labels).to(device)\n",
    "#             logits = model(images)\n",
    "#             label = labels.cpu().numpy().squeeze().flatten()\n",
    "#             prediction = logits.argmax(1).cpu().numpy().squeeze().flatten() # prediction and label are both 1-d array, size: minibatch*640*480\n",
    "#             conf = confusion_matrix(y_true=label, y_pred=prediction, labels=[0,1,2,3,4,5,6,7,8]) # conf is args.n_class*args.n_class matrix, vertical axis: groundtruth, horizontal axis: prediction\n",
    "#             conf_total += conf\n",
    "#             print('Test: %s, epo %s/%s, iter %s/%s, time %s' % (args.model_name, epo, args.epoch_max, it+1, len(test_loader),\n",
    "#                  datetime.datetime.now().replace(microsecond=0)-start_datetime))\n",
    "#     precision, recall, IoU = compute_results(conf_total)\n",
    "#     writer.add_scalar('Test/average_precision',precision.mean(), epo)\n",
    "#     writer.add_scalar('Test/average_recall', recall.mean(), epo)\n",
    "#     writer.add_scalar('Test/average_IoU', IoU.mean(), epo)\n",
    "#     for i in range(len(precision)):\n",
    "#         writer.add_scalar(\"Test(class)/precision_class_%s\" % label_list[i], precision[i], epo)\n",
    "#         writer.add_scalar(\"Test(class)/recall_class_%s\"% label_list[i], recall[i],epo)\n",
    "#         writer.add_scalar('Test(class)/Iou_%s'% label_list[i], IoU[i], epo)\n",
    "#     if epo==0:\n",
    "#         with open(testing_results_file, 'w') as f:\n",
    "#             f.write(\"# %s, initial lr: %s, batch size: %s, date: %s \\n\" %(args.model_name, args.lr_start, args.batch_size, datetime.date.today()))\n",
    "#             f.write(\"# epoch: unlabeled, car, person, bike, curve, car_stop, guardrail, color_cone, bump, average(nan_to_num). (Acc %, IoU %)\\n\")\n",
    "#     with open(testing_results_file, 'a') as f:\n",
    "#         f.write(str(epo)+': ')\n",
    "#         for i in range(len(precision)):\n",
    "#             f.write('%0.4f, %0.4f, ' % (100*recall[i], 100*IoU[i]))\n",
    "#         f.write('%0.4f, %0.4f\\n' % (100*np.mean(np.nan_to_num(recall)), 100*np.mean(np.nan_to_num(IoU))))\n",
    "#     print('saving testing results.')\n",
    "#     with open(testing_results_file, \"r\") as file:\n",
    "#         writer.add_text('testing_results', file.read().replace('\\n', '  \\n'), epo)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     model = eval(args.model_name)(n_class=args.n_class)\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = model.to(device)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_start, momentum=0.9, weight_decay=0.0005)\n",
    "#     scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=args.lr_decay, last_epoch=-1)\n",
    "\n",
    "#     # preparing folders\n",
    "#     weight_dir = os.path.join(\"./runs\", args.model_name)\n",
    "#     print('from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "#     print('weight will be saved in: %s' % weight_dir)\n",
    "\n",
    "#     train_dataset = MF_dataset(data_dir=args.data_dir, split='train', transform=augmentation_methods)\n",
    "#     val_dataset  = MF_dataset(data_dir=args.data_dir, split='val')\n",
    "#     test_dataset = MF_dataset(data_dir=args.data_dir, split='test')\n",
    "\n",
    "#     train_loader  = DataLoader(\n",
    "#         dataset     = train_dataset,\n",
    "#         batch_size  = args.batch_size,\n",
    "#         shuffle     = True,\n",
    "#         num_workers = args.num_workers,\n",
    "#         pin_memory  = True,\n",
    "#         drop_last   = False\n",
    "#     )\n",
    "#     val_loader  = DataLoader(\n",
    "#         dataset     = val_dataset,\n",
    "#         batch_size  = args.batch_size,\n",
    "#         shuffle     = False,\n",
    "#         num_workers = args.num_workers,\n",
    "#         pin_memory  = True,\n",
    "#         drop_last   = False\n",
    "#     )\n",
    "#     test_loader = DataLoader(\n",
    "#         dataset      = test_dataset,\n",
    "#         batch_size   = args.batch_size,\n",
    "#         shuffle      = False,\n",
    "#         num_workers  = args.num_workers,\n",
    "#         pin_memory   = True,\n",
    "#         drop_last    = False\n",
    "#     )\n",
    "#     start_datetime = datetime.datetime.now().replace(microsecond=0)\n",
    "#     accIter = {'train': 0, 'val': 0}\n",
    "#     for epo in range(args.epoch_from, args.epoch_max):\n",
    "#         print('\\ntrain %s, epo #%s begin...' % (args.model_name, epo))\n",
    "#         train(epo, model, train_loader, optimizer)\n",
    "#         validation(epo, model, val_loader)\n",
    "\n",
    "#         checkpoint_model_file = os.path.join(weight_dir, str(epo) + '.pth')\n",
    "#         print('saving check point %s: ' % checkpoint_model_file)\n",
    "#         torch.save(model.state_dict(), checkpoint_model_file)\n",
    "\n",
    "#         testing(epo, model, test_loader)\n",
    "#         scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with cpu\n",
      "from epoch 0 / 10\n",
      "\n",
      "train Fusion, epo #0 begin...\n",
      "0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtrain \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, epo #\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m begin...\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (args\u001b[38;5;241m.\u001b[39mmodel_name, epo))\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#scheduler.step() # if using pytorch 0.4.1, please put this statement here \u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epo, model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, labels)\n\u001b[1;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 35\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multimodel/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multimodel/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multimodel/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multimodel/lib/python3.12/site-packages/torch/optim/sgd.py:123\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m momentum_buffer_list: List[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    119\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    120\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[1;32m    121\u001b[0m )\n\u001b[0;32m--> 123\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multimodel/lib/python3.12/site-packages/torch/optim/sgd.py:298\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 298\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multimodel/lib/python3.12/site-packages/torch/optim/sgd.py:344\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    342\u001b[0m     momentum_buffer_list[i] \u001b[38;5;241m=\u001b[39m buf\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dampening)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov:\n\u001b[1;32m    347\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(buf, alpha\u001b[38;5;241m=\u001b[39mmomentum)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Train with pytorch')\n",
    "############################################################################################# \n",
    "parser.add_argument('--model_name', '-m', type=str, default='Fusion')\n",
    "#batch_size: RTFNet-152: 2; RTFNet-101: 2; RTFNet-50: 3; RTFNet-34: 10; RTFNet-18: 15;\n",
    "parser.add_argument('--batch_size', '-b', type=int, default=2) \n",
    "parser.add_argument('--lr_start', '-ls', type=float, default=0.01)\n",
    "parser.add_argument('--gpu', '-g', type=int, default=0)\n",
    "parser.add_argument('--lr_decay', '-ld', type=float, default=0.95)\n",
    "parser.add_argument('--epoch_max', '-em', type=int, default=10)\n",
    "parser.add_argument('--epoch_from', '-ef', type=int, default=0) \n",
    "parser.add_argument('--n_class', '-nc', type=int, default=9)\n",
    "parser.add_argument('--data_dir', '-dr', type=str, default='./dataset/')\n",
    "args, unknown = parser.parse_known_args()\n",
    "# 数据增强\n",
    "augmentation_methods = [\n",
    "    RandomFlip(prob=0.5),\n",
    "    RandomCrop(crop_rate=0.1, prob=1.0)\n",
    "]\n",
    "writer = SummaryWriter()\n",
    "# 运行设备选择\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def update_weights(self, current_iou):\n",
    "    # 基于当前IoU调整权重\n",
    "    # 这里简化逻辑: IoU提高则增加rgb权重，降低thermal权重\n",
    "    delta = self.momentum * (current_iou - 0.5)  # 假设0.5是基准值\n",
    "    \n",
    "    # 更新权重\n",
    "    new_weights = self.fusion_weights.clone()\n",
    "    new_weights[0] += delta  # rgb权重\n",
    "    new_weights[1] -= delta  # thermal权重\n",
    "    \n",
    "    # 限制权重范围\n",
    "    new_weights = torch.clamp(new_weights, 0.1, 0.9)\n",
    "    \n",
    "    # 更新并存储历史\n",
    "    self.fusion_weights.copy_(new_weights)\n",
    "    self.weight_history[self.history_index] = new_weights\n",
    "    self.history_index = (self.history_index + 1) % 100\n",
    "\n",
    "def train(epo, model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for it, (images, labels, names) in enumerate(train_loader):\n",
    "        # 读取数据\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        # 固定梯度\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        learning_rate = 0\n",
    "        for param_group in optimizer.param_groups:\n",
    "            learning_rate = param_group['lr']\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = eval(args.model_name)(n_class=args.n_class)\n",
    "    model = model.to(device)\n",
    "    print(\"Training with {}\".format(device))\n",
    "    # 优化器\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_start, momentum=0.9, weight_decay=0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=args.lr_decay, last_epoch=-1)\n",
    "    \n",
    "    # preparing folders\n",
    "    weight_dir = os.path.join(\"./runs\", args.model_name)\n",
    "    print('from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "\n",
    "    train_dataset = MF_dataset(data_dir=args.data_dir, split='train', transform=augmentation_methods)\n",
    "    val_dataset  = MF_dataset(data_dir=args.data_dir, split='val')\n",
    "    test_dataset = MF_dataset(data_dir=args.data_dir, split='test')\n",
    "\n",
    "    train_loader  = DataLoader(\n",
    "        dataset     = train_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = True,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    for epo in range(args.epoch_from, args.epoch_max):\n",
    "        print('\\ntrain %s, epo #%s begin...' % (args.model_name, epo))\n",
    "        train(epo, model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 1/20, ('01500D',), time cost: 1217.87 ms, demo result saved.\n",
      "frame 2/20, ('01501D',), time cost: 1078.46 ms, demo result saved.\n",
      "frame 3/20, ('01502D',), time cost: 995.38 ms, demo result saved.\n",
      "frame 4/20, ('01503D',), time cost: 991.80 ms, demo result saved.\n",
      "frame 5/20, ('01504D',), time cost: 962.59 ms, demo result saved.\n",
      "frame 6/20, ('01505D',), time cost: 945.19 ms, demo result saved.\n",
      "frame 7/20, ('01506D',), time cost: 935.76 ms, demo result saved.\n",
      "frame 8/20, ('01507D',), time cost: 942.15 ms, demo result saved.\n",
      "frame 9/20, ('01508D',), time cost: 993.62 ms, demo result saved.\n",
      "frame 10/20, ('01509D',), time cost: 1260.97 ms, demo result saved.\n",
      "frame 11/20, ('01200N',), time cost: 1043.54 ms, demo result saved.\n",
      "frame 12/20, ('01201N',), time cost: 966.76 ms, demo result saved.\n",
      "frame 13/20, ('01202N',), time cost: 951.44 ms, demo result saved.\n",
      "frame 14/20, ('01203N',), time cost: 971.71 ms, demo result saved.\n",
      "frame 15/20, ('01204N',), time cost: 949.03 ms, demo result saved.\n",
      "frame 16/20, ('01205N',), time cost: 957.51 ms, demo result saved.\n",
      "frame 17/20, ('01206N',), time cost: 1019.71 ms, demo result saved.\n",
      "frame 18/20, ('01207N',), time cost: 962.18 ms, demo result saved.\n",
      "frame 19/20, ('01208N',), time cost: 967.74 ms, demo result saved.\n",
      "frame 20/20, ('01209N',), time cost: 963.62 ms, demo result saved.\n",
      "Accomplished!!\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Test with pytorch')\n",
    "\n",
    "parser.add_argument('--model_name', '-m', type=str, default='Fusion')\n",
    "parser.add_argument('--weight_name', '-w', type=str, default='RTFNET_152') # RTFNet_152, RTFNet_50, please change the number of layers in the network file\n",
    "parser.add_argument('--file_name', '-fi', type=str, default='final.pth')\n",
    "parser.add_argument('--dataset_split', '-d', type=str, default='test') # test, test_day, test_night\n",
    "parser.add_argument('--img_height', '-ih', type=int, default=480)\n",
    "parser.add_argument('--img_width', '-iw', type=int, default=640)\n",
    "parser.add_argument('--num_workers', '-j', type=int, default=8)\n",
    "parser.add_argument('--n_class', '-nc', type=int, default=9)\n",
    "parser.add_argument('--data_dir', '-dr', type=str, default='./dataset/')\n",
    "parser.add_argument('--model_dir', '-wd', type=str, default='./weights_backup/')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.file_name = \"final.pth\"\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_dir = os.path.join(args.model_dir, args.weight_name)\n",
    "    # if os.path.exists(model_dir) is False:\n",
    "    #     sys.exit(\"the %s does not exit.\" %(model_dir))\n",
    "    model_file = os.path.join(model_dir, args.file_name)\n",
    "\n",
    "\n",
    "    conf_total = np.zeros((args.n_class, args.n_class))\n",
    "    model = eval(args.model_name)(n_class=args.n_class)\n",
    "    model = model.to(device)\n",
    "\n",
    "    pretrained_weight = torch.load('/Users/qiaopeng/Desktop/多源信号/多模态/RTFNet-master/weights_backup/RTFNet_152/final.pth', map_location='cpu', weights_only=True)\n",
    "    own_state = model.state_dict()\n",
    "    for name, param in pretrained_weight.items():\n",
    "        if name not in own_state:\n",
    "            continue\n",
    "        own_state[name].copy_(param)\n",
    "\n",
    "    batch_size = 1\n",
    "    test_dataset  = MF_dataset(data_dir=args.data_dir, split=args.dataset_split, input_h=args.img_height, input_w=args.img_width)\n",
    "    test_loader  = DataLoader(\n",
    "        dataset     = test_dataset,\n",
    "        batch_size  = batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    ave_time_cost = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for it, (images, labels, names) in enumerate(test_loader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            start_time = time.time()\n",
    "            logits = model(images)  # logits.size(): mini_batch*num_class*480*640\n",
    "            end_time = time.time()\n",
    "            if it>=5: # # ignore the first 5 frames\n",
    "                ave_time_cost += (end_time-start_time)\n",
    "            # convert tensor to numpy 1d array\n",
    "            label = labels.detach().cpu().numpy().squeeze().flatten()\n",
    "            prediction = logits.argmax(1).detach().cpu().numpy().squeeze().flatten() # prediction and label are both 1-d array, size: minibatch*640*480\n",
    "            # generate confusion matrix frame-by-frame\n",
    "            # conf = confusion_matrix(y_true=label, y_pred=prediction, labels=[0,1,2,3,4,5,6,7,8]) # conf is an n_class*n_class matrix, vertical axis: groundtruth, horizontal axis: prediction\n",
    "            # conf_total += conf\n",
    "            # save demo images\n",
    "            visualize(image_name=names, predictions=logits.argmax(1), weight_name=args.weight_name)\n",
    "            print(\"frame %d/%d, %s, time cost: %.2f ms, demo result saved.\"\n",
    "                  %(it+1, len(test_loader), names, (end_time-start_time)*1000))\n",
    "    print('Accomplished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pic = \"1500D\"\n",
    "# 指定图像路径（例如测试集中的第一张图像）\n",
    "image_path = 'runs/Predict_RTFNET_152_0{}.png'.format(pic)  # 根据实际路径调整\n",
    "image_path1 = 'runs/Pred_RTFNet_152_0{}.png'.format(pic)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "img = plt.imread(image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 隐藏坐标轴\n",
    "plt.title(\"Original\")\n",
    "plt.subplot(1, 2, 2)\n",
    "img1 = plt.imread(image_path1)\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')  # 隐藏坐标轴\n",
    "plt.title(\"Modified\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
