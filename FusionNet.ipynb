{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, time, datetime, sys, shutil, stat, torch\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from util.MF_dataset import MF_dataset\n",
    "from util.util import compute_results, visualize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import savemat\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from util.augmentation import RandomFlip, RandomCrop, RandomCropOut, RandomBrightness, RandomNoise\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import ResNet152_Weights, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.attetion = nn.Sequential(\n",
    "            nn.Conv2d(channels * 2, channels // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 2, 2, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.rgb_confidence = nn.Parameter(torch.tensor(1.0))\n",
    "        self.thermal_confidence = nn.Parameter(torch.tensor(1.0))  # 权重更新动量系数\n",
    "\n",
    "    def update(self, rgb_purity, thermal_purity):\n",
    "        self.rgb_prior = self.momentum * self.rgb_prior + (1-self.momentum)* rgb_purity\n",
    "        self.thermal_prior = self.momentum * self.thermal_prior + (1-self.momentum) * thermal_purity\n",
    "        self.rgb_prior.data.clamp_(0.1, 1.0)\n",
    "        self.thermal_prior.data.clamp_(0.1, 1.0)\n",
    "\n",
    "    def forward(self, rgb_feat, thermal_feat):\n",
    "        combined = torch.cat([rgb_feat, thermal_feat], dim=1)\n",
    "        attention_weights = self.attention(combined)  # [B,2,H,W]\n",
    "\n",
    "        # 将置信度参数转换为与attention_weights相同的维度\n",
    "        rgb_conf = torch.sigmoid(self.rgb_confidence).view(1,1,1,1)  # [1,1,1,1]\n",
    "        thermal_conf = torch.sigmoid(self.thermal_confidence).view(1,1,1,1)\n",
    "\n",
    "        # 动态调整权重（关键修改点）\n",
    "        adjusted_weights = torch.cat([\n",
    "            attention_weights[:,0:1] * rgb_conf * self.rgb_prior,\n",
    "            attention_weights[:,1:2] * thermal_conf * self.thermal_prior\n",
    "        ], dim=1)\n",
    "\n",
    "        # 重新归一化\n",
    "        norm_weights = adjusted_weights / (adjusted_weights.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        return rgb_feat * norm_weights[:,0:1] + thermal_feat * norm_weights[:,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息瓶颈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransBottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, upsample=None):\n",
    "        super(TransBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        if upsample is not None and stride != 1:\n",
    "            self.conv3 = nn.ConvTranspose2d(planes, planes, kernel_size=2, stride=stride, padding=0, bias=False)\n",
    "        else:\n",
    "            self.conv3 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.upsample = upsample\n",
    "        self.stride = stride\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):  # 残差连接\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            residual = self.upsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTFNet(nn.Module):\n",
    "    # 初始化\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        self.num_resnet_layers = 152\n",
    "\n",
    "        if self.num_resnet_layers == 50:\n",
    "            resnet_raw_model1 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            resnet_raw_model2 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            self.inplanes = 2048\n",
    "        elif self.num_resnet_layers == 152:\n",
    "            resnet_raw_model1 = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "            resnet_raw_model2 = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "            self.inplanes = 2048\n",
    "\n",
    "        # 基础层\n",
    "        self.encoder_thermal_bn1 = resnet_raw_model1.bn1\n",
    "        self.encoder_thermal_relu = resnet_raw_model1.relu\n",
    "        self.encoder_thermal_pool = resnet_raw_model1.maxpool\n",
    "        self.encoder_rgb_bn1 = resnet_raw_model2.bn1\n",
    "        self.encoder_rgb_relu = resnet_raw_model2.relu\n",
    "        self.encoder_rgb_pool = resnet_raw_model2.maxpool\n",
    "        # 编码器\n",
    "        # Thermal & RGB 第一层\n",
    "        self.encoder_thermal_conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.encoder_thermal_conv1.weight.data = torch.unsqueeze(torch.mean(resnet_raw_model1.conv1.weight.data, dim=1), dim=1)\n",
    "        self.encoder_rgb_conv1 = resnet_raw_model2.conv1\n",
    "        # Thermal & RGB 第二层\n",
    "        self.encoder_thermal_layer1 = resnet_raw_model1.layer1\n",
    "        self.encoder_rgb_layer1 = resnet_raw_model2.layer1\n",
    "        # Thermal & RGB 第三层\n",
    "        self.encoder_thermal_layer2 = resnet_raw_model1.layer2\n",
    "        self.encoder_rgb_layer2 = resnet_raw_model2.layer2\n",
    "        # Thermal & RGB 第四层\n",
    "        self.encoder_thermal_layer3 = resnet_raw_model1.layer3\n",
    "        self.encoder_rgb_layer3 = resnet_raw_model2.layer3\n",
    "        # Thermal & RGB 第五层\n",
    "        self.encoder_thermal_layer4 = resnet_raw_model1.layer4\n",
    "        self.encoder_rgb_layer4 = resnet_raw_model2.layer4\n",
    "        # 权重存储\n",
    "        self.a = nn.Parameter(torch.tensor(1.0))\n",
    "        self.register_buffer('a_history', torch.zeros(100))\n",
    "        self.register_buffer('history_idx', torch.tensor(0))\n",
    "        self.register_buffer('valid_count', torch.tensor(0))\n",
    "\n",
    "        # 融合层 通道数待定\n",
    "        # self.fusion = AttentionFusion()\n",
    "\n",
    "        # 解码器\n",
    "        self.deconv1 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv2 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv3 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv4 = self._make_transpose_layer(TransBottleneck, self.inplanes // 2, 2, stride=2)\n",
    "        self.deconv5 = self._make_transpose_layer(TransBottleneck, n_class, 2, stride=2)    \n",
    "\n",
    "    def _make_transpose_layer(self, block, planes, blocks, stride=1):\n",
    "        upsample = None\n",
    "        if stride != 1:\n",
    "            upsample = nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.inplanes, planes, kernel_size=2, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        elif self.inplanes != planes:\n",
    "            upsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        for m in upsample.modules():  \n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        layers = []\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, self.inplanes))\n",
    "        layers.append(block(self.inplanes, planes, stride, upsample))\n",
    "        self.inplanes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"强制子类实现forward方法\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion(RTFNet):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__(n_class)\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        rgb = input[:, :3]\n",
    "        thermal = input[:, 3:]\n",
    "\n",
    "        rgb = self.encoder_rgb_conv1(rgb) # (240, 320)\n",
    "        rgb = self.encoder_rgb_bn1(rgb) # (240, 320)\n",
    "        rgb = self.encoder_rgb_relu(rgb) # (240, 320)\n",
    "\n",
    "        thermal = self.encoder_thermal_conv1(thermal) # (240, 320)\n",
    "        thermal = self.encoder_thermal_bn1(thermal) # (240, 320)\n",
    "        thermal = self.encoder_thermal_relu(thermal) # (240, 320)\n",
    "    \n",
    "        fuse = rgb + thermal  # 融合一次\n",
    "\n",
    "        rgb = self.encoder_rgb_pool(rgb) # (120, 160)\n",
    "        thermal = self.encoder_thermal_pool(thermal) # (120, 160)\n",
    "\n",
    "        rgb = self.encoder_rgb_layer1(rgb) # (120, 160)\n",
    "        thermal = self.encoder_thermal_layer1(thermal) # (120, 160)\n",
    "\n",
    "        rgb = rgb + thermal\n",
    "\n",
    "        rgb = self.encoder_rgb_layer2(rgb) # (60, 80)\n",
    "        thermal = self.encoder_thermal_layer2(thermal) # (60, 80)\n",
    "\n",
    "        rgb = rgb + thermal\n",
    "\n",
    "        rgb = self.encoder_rgb_layer3(rgb) # (30, 40)\n",
    "        thermal = self.encoder_thermal_layer3(thermal) # (30, 40)\n",
    "\n",
    "        rgb = rgb + thermal\n",
    "\n",
    "        rgb = self.encoder_rgb_layer4(rgb) # (15, 20)\n",
    "        thermal = self.encoder_thermal_layer4(thermal) # (15, 20)\n",
    "\n",
    "        a = torch.sigmoid(self.a) * 2\n",
    "        fuse = a * rgb + (2 - a) * thermal\n",
    "\n",
    "        fuse = self.deconv1(fuse) # (30, 40)\n",
    "        fuse = self.deconv2(fuse) # (60, 80)\n",
    "        fuse = self.deconv3(fuse) # (120, 160)\n",
    "        fuse = self.deconv4(fuse) # (240, 320)\n",
    "        fuse = self.deconv5(fuse) # (480, 640)\n",
    "\n",
    "        return fuse\n",
    "\n",
    "    def update_iou(self, cur_iou):\n",
    "        with torch.no_grad():\n",
    "            idx = self.history_idx.item()\n",
    "            self.a_history[idx] = cur_iou\n",
    "            self.history_idx.copy_((idx + 1) % 100)\n",
    "            self.valid_count.copy_(min(self.valid_count + 1, 100))\n",
    "    \n",
    "    def get_recent(self, n=3):\n",
    "        with torch.no_grad():\n",
    "            if self.valid_count < n:\n",
    "                return None\n",
    "            idx = self.history_idx.item()\n",
    "            indices = [(idx - i - 1) % 100 for i in range(n)]\n",
    "            return self.a_history[indices]\n",
    "\n",
    "    def adjust_weight(self):\n",
    "        with torch.no_grad():\n",
    "            recent_iou = self.get_recent(3)\n",
    "            if recent_iou is None:\n",
    "                return \n",
    "            \n",
    "            cur, pre1, pre2 = recent_iou\n",
    "            # 计算比较\n",
    "            avg_improvement = cur - (pre1 + pre2) / 2\n",
    "            if avg_improvement > 0:  # 效果提升\n",
    "                self.a.data *= (1 + 0.05)\n",
    "            else:  # 效果下降\n",
    "                self.a.data *= (1 - 0.05)\n",
    "\n",
    "            self.a.data.clamp_(0.1, 2.0)\n",
    "            self.a.data = 0.1 * self.a + 0.9 * self.a.detach()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test():\n",
    "    num_minibatch = 1\n",
    "    rgb = torch.randn(num_minibatch, 3, 480, 640)\n",
    "    thermal = torch.randn(num_minibatch, 1, 480, 640)\n",
    "    rtf_net = Fusion(9)\n",
    "    input = torch.cat((rgb, thermal), dim=1)\n",
    "    rtf_net(input)\n",
    "    # print('The model: ', rtf_net.modules)\n",
    "    print('Accomplished！')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unit_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='Train with pytorch')\n",
    "# parser.add_argument('--model_name', '-m', type=str, default='RTFNet')\n",
    "# parser.add_argument('--batch_size', '-b', type=int, default=2)\n",
    "# parser.add_argument('--lr_start', '-ls', type=float, default=0.01)\n",
    "# parser.add_argument('--gpu', '-g', type=int, default=0)\n",
    "# parser.add_argument('--lr_decay', '-ld', type=float, default=0.95)\n",
    "# parser.add_argument('--epoch_max', '-em', type=int, default=1)\n",
    "# parser.add_argument('--epoch_from', '-ef', type=int, default=0)\n",
    "# parser.add_argument('--num_workers', '-j', type=int, default=2)\n",
    "# parser.add_argument('--n_class', '-nc', type=int, default=9)\n",
    "# parser.add_argument('--data_dir', '-dr', type=str, default='./dataset/')\n",
    "# args, unknown = parser.parse_known_args()\n",
    "\n",
    "# augmentation_methods = [\n",
    "#     RandomFlip(prob=0.5),\n",
    "#     RandomCrop(crop_rate=0.1, prob=1.0),\n",
    "#     # RandomCropOut(crop_rate=0.2, prob=1.0),\n",
    "#     # RandomBrightness(bright_range=0.15, prob=0.9),\n",
    "#     # RandomNoise(noise_range=5, prob=0.9),\n",
    "# ]\n",
    "# writer = SummaryWriter()\n",
    "# def train(epo, model, train_loader, optimizer):\n",
    "#     model.train()\n",
    "#     for it, (images, labels, names) in enumerate(train_loader):\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         images = Variable(images).to(device)\n",
    "#         labels = Variable(labels).to(device)\n",
    "#         start_t = time.time() # time.time() returns the current time\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(images)\n",
    "#         loss = F.cross_entropy(logits, labels)  # Note that the cross_entropy function has already include the softmax function\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         lr_this_epo=0\n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             lr_this_epo = param_group['lr']\n",
    "#         print('Train: %s, epo %s/%s, iter %s/%s, lr %.8f, %.2f img/sec, loss %.4f, time %s' \\\n",
    "#             % (args.model_name, epo, args.epoch_max, it+1, len(train_loader), lr_this_epo, len(names)/(time.time()-start_t), float(loss),\n",
    "#               datetime.datetime.now().replace(microsecond=0)-start_datetime))\n",
    "#         if accIter['train'] % 1 == 0:\n",
    "#             writer.add_scalar('Train/loss', loss, accIter['train'])\n",
    "#         view_figure = True # note that I have not colorized the GT and predictions here\n",
    "#         if accIter['train'] % 500 == 0:\n",
    "#             if view_figure:\n",
    "#                 input_rgb_images = vutils.make_grid(images[:,:3], nrow=8, padding=10) # can only display 3-channel images, so images[:,:3]\n",
    "#                 writer.add_image('Train/input_rgb_images', input_rgb_images, accIter['train'])\n",
    "#                 scale = max(1, 255//args.n_class) # label (0,1,2..) is invisable, multiply a constant for visualization\n",
    "#                 groundtruth_tensor = labels.unsqueeze(1) * scale  # mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                 groundtruth_tensor = torch.cat((groundtruth_tensor, groundtruth_tensor, groundtruth_tensor), 1)  # change to 3-channel for visualization\n",
    "#                 groudtruth_images = vutils.make_grid(groundtruth_tensor, nrow=8, padding=10)\n",
    "#                 writer.add_image('Train/groudtruth_images', groudtruth_images, accIter['train'])\n",
    "#                 predicted_tensor = logits.argmax(1).unsqueeze(1) * scale # mini_batch*args.n_class*480*640 -> mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                 predicted_tensor = torch.cat((predicted_tensor, predicted_tensor, predicted_tensor),1) # change to 3-channel for visualization, mini_batch*1*480*640\n",
    "#                 predicted_images = vutils.make_grid(predicted_tensor, nrow=8, padding=10)\n",
    "#                 writer.add_image('Train/predicted_images', predicted_images, accIter['train'])\n",
    "#         accIter['train'] = accIter['train'] + 1\n",
    "\n",
    "\n",
    "# def validation(epo, model, val_loader):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for it, (images, labels, names) in enumerate(val_loader):\n",
    "#             device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#             images = Variable(images).to(device)\n",
    "#             labels = Variable(labels).to(device)\n",
    "#             start_t = time.time() # time.time() returns the current time\n",
    "#             logits = model(images)\n",
    "#             loss = F.cross_entropy(logits, labels)  # Note that the cross_entropy function has already include the softmax function\n",
    "#             print('Val: %s, epo %s/%s, iter %s/%s, %.2f img/sec, loss %.4f, time %s' \\\n",
    "#                   % (args.model_name, epo, args.epoch_max, it + 1, len(val_loader), len(names)/(time.time()-start_t), float(loss),\n",
    "#                     datetime.datetime.now().replace(microsecond=0)-start_datetime))\n",
    "#             if accIter['val'] % 1 == 0:\n",
    "#                 writer.add_scalar('Validation/loss', loss, accIter['val'])\n",
    "#             view_figure = False  # note that I have not colorized the GT and predictions here\n",
    "#             if accIter['val'] % 100 == 0:\n",
    "#                 if view_figure:\n",
    "#                     input_rgb_images = vutils.make_grid(images[:, :3], nrow=8, padding=10)  # can only display 3-channel images, so images[:,:3]\n",
    "#                     writer.add_image('Validation/input_rgb_images', input_rgb_images, accIter['val'])\n",
    "#                     scale = max(1, 255 // args.n_class)  # label (0,1,2..) is invisable, multiply a constant for visualization\n",
    "#                     groundtruth_tensor = labels.unsqueeze(1) * scale  # mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                     groundtruth_tensor = torch.cat((groundtruth_tensor, groundtruth_tensor, groundtruth_tensor), 1)  # change to 3-channel for visualization\n",
    "#                     groudtruth_images = vutils.make_grid(groundtruth_tensor, nrow=8, padding=10)\n",
    "#                     writer.add_image('Validation/groudtruth_images', groudtruth_images, accIter['val'])\n",
    "#                     predicted_tensor = logits.argmax(1).unsqueeze(1)*scale  # mini_batch*args.n_class*480*640 -> mini_batch*480*640 -> mini_batch*1*480*640\n",
    "#                     predicted_tensor = torch.cat((predicted_tensor, predicted_tensor, predicted_tensor), 1)  # change to 3-channel for visualization, mini_batch*1*480*640\n",
    "#                     predicted_images = vutils.make_grid(predicted_tensor, nrow=8, padding=10)\n",
    "#                     writer.add_image('Validation/predicted_images', predicted_images, accIter['val'])\n",
    "#             accIter['val'] += 1\n",
    "\n",
    "# def testing(epo, model, test_loader):\n",
    "#     model.eval()\n",
    "#     conf_total = np.zeros((args.n_class, args.n_class))\n",
    "#     label_list = [\"unlabeled\", \"car\", \"person\", \"bike\", \"curve\", \"car_stop\", \"guardrail\", \"color_cone\", \"bump\"]\n",
    "#     testing_results_file = os.path.join(weight_dir, 'testing_results_file.txt')\n",
    "#     with torch.no_grad():\n",
    "#         for it, (images, labels, names) in enumerate(test_loader):\n",
    "#             device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#             images = Variable(images).to(device)\n",
    "#             labels = Variable(labels).to(device)\n",
    "#             logits = model(images)\n",
    "#             label = labels.cpu().numpy().squeeze().flatten()\n",
    "#             prediction = logits.argmax(1).cpu().numpy().squeeze().flatten() # prediction and label are both 1-d array, size: minibatch*640*480\n",
    "#             conf = confusion_matrix(y_true=label, y_pred=prediction, labels=[0,1,2,3,4,5,6,7,8]) # conf is args.n_class*args.n_class matrix, vertical axis: groundtruth, horizontal axis: prediction\n",
    "#             conf_total += conf\n",
    "#             print('Test: %s, epo %s/%s, iter %s/%s, time %s' % (args.model_name, epo, args.epoch_max, it+1, len(test_loader),\n",
    "#                  datetime.datetime.now().replace(microsecond=0)-start_datetime))\n",
    "#     precision, recall, IoU = compute_results(conf_total)\n",
    "#     writer.add_scalar('Test/average_precision',precision.mean(), epo)\n",
    "#     writer.add_scalar('Test/average_recall', recall.mean(), epo)\n",
    "#     writer.add_scalar('Test/average_IoU', IoU.mean(), epo)\n",
    "#     for i in range(len(precision)):\n",
    "#         writer.add_scalar(\"Test(class)/precision_class_%s\" % label_list[i], precision[i], epo)\n",
    "#         writer.add_scalar(\"Test(class)/recall_class_%s\"% label_list[i], recall[i],epo)\n",
    "#         writer.add_scalar('Test(class)/Iou_%s'% label_list[i], IoU[i], epo)\n",
    "#     if epo==0:\n",
    "#         with open(testing_results_file, 'w') as f:\n",
    "#             f.write(\"# %s, initial lr: %s, batch size: %s, date: %s \\n\" %(args.model_name, args.lr_start, args.batch_size, datetime.date.today()))\n",
    "#             f.write(\"# epoch: unlabeled, car, person, bike, curve, car_stop, guardrail, color_cone, bump, average(nan_to_num). (Acc %, IoU %)\\n\")\n",
    "#     with open(testing_results_file, 'a') as f:\n",
    "#         f.write(str(epo)+': ')\n",
    "#         for i in range(len(precision)):\n",
    "#             f.write('%0.4f, %0.4f, ' % (100*recall[i], 100*IoU[i]))\n",
    "#         f.write('%0.4f, %0.4f\\n' % (100*np.mean(np.nan_to_num(recall)), 100*np.mean(np.nan_to_num(IoU))))\n",
    "#     print('saving testing results.')\n",
    "#     with open(testing_results_file, \"r\") as file:\n",
    "#         writer.add_text('testing_results', file.read().replace('\\n', '  \\n'), epo)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     model = eval(args.model_name)(n_class=args.n_class)\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = model.to(device)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_start, momentum=0.9, weight_decay=0.0005)\n",
    "#     scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=args.lr_decay, last_epoch=-1)\n",
    "\n",
    "#     # preparing folders\n",
    "#     weight_dir = os.path.join(\"./runs\", args.model_name)\n",
    "#     print('from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "#     print('weight will be saved in: %s' % weight_dir)\n",
    "\n",
    "#     train_dataset = MF_dataset(data_dir=args.data_dir, split='train', transform=augmentation_methods)\n",
    "#     val_dataset  = MF_dataset(data_dir=args.data_dir, split='val')\n",
    "#     test_dataset = MF_dataset(data_dir=args.data_dir, split='test')\n",
    "\n",
    "#     train_loader  = DataLoader(\n",
    "#         dataset     = train_dataset,\n",
    "#         batch_size  = args.batch_size,\n",
    "#         shuffle     = True,\n",
    "#         num_workers = args.num_workers,\n",
    "#         pin_memory  = True,\n",
    "#         drop_last   = False\n",
    "#     )\n",
    "#     val_loader  = DataLoader(\n",
    "#         dataset     = val_dataset,\n",
    "#         batch_size  = args.batch_size,\n",
    "#         shuffle     = False,\n",
    "#         num_workers = args.num_workers,\n",
    "#         pin_memory  = True,\n",
    "#         drop_last   = False\n",
    "#     )\n",
    "#     test_loader = DataLoader(\n",
    "#         dataset      = test_dataset,\n",
    "#         batch_size   = args.batch_size,\n",
    "#         shuffle      = False,\n",
    "#         num_workers  = args.num_workers,\n",
    "#         pin_memory   = True,\n",
    "#         drop_last    = False\n",
    "#     )\n",
    "#     start_datetime = datetime.datetime.now().replace(microsecond=0)\n",
    "#     accIter = {'train': 0, 'val': 0}\n",
    "#     for epo in range(args.epoch_from, args.epoch_max):\n",
    "#         print('\\ntrain %s, epo #%s begin...' % (args.model_name, epo))\n",
    "#         train(epo, model, train_loader, optimizer)\n",
    "#         validation(epo, model, val_loader)\n",
    "\n",
    "#         checkpoint_model_file = os.path.join(weight_dir, str(epo) + '.pth')\n",
    "#         print('saving check point %s: ' % checkpoint_model_file)\n",
    "#         torch.save(model.state_dict(), checkpoint_model_file)\n",
    "\n",
    "#         testing(epo, model, test_loader)\n",
    "#         scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Train with pytorch')\n",
    "############################################################################################# \n",
    "parser.add_argument('--model_name', '-m', type=str, default='Fusion')\n",
    "#batch_size: RTFNet-152: 2; RTFNet-101: 2; RTFNet-50: 3; RTFNet-34: 10; RTFNet-18: 15;\n",
    "parser.add_argument('--batch_size', '-b', type=int, default=2) \n",
    "parser.add_argument('--lr_start', '-ls', type=float, default=0.01)\n",
    "parser.add_argument('--gpu', '-g', type=int, default=0)\n",
    "parser.add_argument('--lr_decay', '-ld', type=float, default=0.95)\n",
    "parser.add_argument('--epoch_max', '-em', type=int, default=10)\n",
    "parser.add_argument('--epoch_from', '-ef', type=int, default=0) \n",
    "parser.add_argument('--n_class', '-nc', type=int, default=9)\n",
    "parser.add_argument('--data_dir', '-dr', type=str, default='./dataset/')\n",
    "args, unknown = parser.parse_known_args()\n",
    "# 数据增强\n",
    "augmentation_methods = [\n",
    "    RandomFlip(prob=0.5),\n",
    "    RandomCrop(crop_rate=0.1, prob=1.0)\n",
    "]\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def calculate_iou(pred, target, n_class):\n",
    "    ious = []\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    for cls in range(n_class):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().float()\n",
    "        union = (pred_inds | target_inds).sum().float()\n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)  # 避免除零\n",
    "        ious.append(iou.item())\n",
    "    return np.mean(ious)\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_iou = 0\n",
    "\n",
    "    for it, (images, labels, names) in enumerate(train_loader):\n",
    "        # 读取数据\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        # 固定梯度\n",
    "        logits = model(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cur_iou = calculate_iou(logits, labels, args.n_class)\n",
    "            total_iou += cur_iou\n",
    "        \n",
    "        model.update_iou(cur_iou)\n",
    "        model.adjust_weight()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = eval(args.model_name)(n_class=args.n_class)\n",
    "    model = model.to(device)\n",
    "    print(\"Training with {}\".format(device))\n",
    "    # 优化器\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_start, momentum=0.9, weight_decay=0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=args.lr_decay, last_epoch=-1)\n",
    "    \n",
    "    # preparing folders\n",
    "    weight_dir = os.path.join(\"./runs\", args.model_name)\n",
    "    print('from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "\n",
    "    train_dataset = MF_dataset(data_dir=args.data_dir, split='train', transform=augmentation_methods)\n",
    "    val_dataset  = MF_dataset(data_dir=args.data_dir, split='val')\n",
    "    test_dataset = MF_dataset(data_dir=args.data_dir, split='test')\n",
    "\n",
    "    train_loader  = DataLoader(\n",
    "        dataset     = train_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = True,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    for epo in range(args.epoch_from, args.epoch_max):\n",
    "        print('\\ntrain %s, epo #%s begin...' % (args.model_name, epo))\n",
    "        train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Test with pytorch')\n",
    "\n",
    "parser.add_argument('--model_name', '-m', type=str, default='Fusion')\n",
    "parser.add_argument('--weight_name', '-w', type=str, default='RTFNET_152') # RTFNet_152, RTFNet_50, please change the number of layers in the network file\n",
    "parser.add_argument('--file_name', '-fi', type=str, default='final.pth')\n",
    "parser.add_argument('--dataset_split', '-d', type=str, default='test') # test, test_day, test_night\n",
    "parser.add_argument('--img_height', '-ih', type=int, default=480)\n",
    "parser.add_argument('--img_width', '-iw', type=int, default=640)\n",
    "parser.add_argument('--num_workers', '-j', type=int, default=8)\n",
    "parser.add_argument('--n_class', '-nc', type=int, default=9)\n",
    "parser.add_argument('--data_dir', '-dr', type=str, default='./dataset/')\n",
    "parser.add_argument('--model_dir', '-wd', type=str, default='./weights_backup/')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.file_name = \"final.pth\"\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_dir = os.path.join(args.model_dir, args.weight_name)\n",
    "    # if os.path.exists(model_dir) is False:\n",
    "    #     sys.exit(\"the %s does not exit.\" %(model_dir))\n",
    "    model_file = os.path.join(model_dir, args.file_name)\n",
    "\n",
    "\n",
    "    conf_total = np.zeros((args.n_class, args.n_class))\n",
    "    model = eval(args.model_name)(n_class=args.n_class)\n",
    "    model = model.to(device)\n",
    "\n",
    "    pretrained_weight = torch.load('/Users/qiaopeng/Desktop/多源信号/多模态/RTFNet-master/weights_backup/RTFNet_152/final.pth', map_location='cpu', weights_only=True)\n",
    "    own_state = model.state_dict()\n",
    "    for name, param in pretrained_weight.items():\n",
    "        if name not in own_state:\n",
    "            continue\n",
    "        own_state[name].copy_(param)\n",
    "\n",
    "    batch_size = 1\n",
    "    test_dataset  = MF_dataset(data_dir=args.data_dir, split=args.dataset_split, input_h=args.img_height, input_w=args.img_width)\n",
    "    test_loader  = DataLoader(\n",
    "        dataset     = test_dataset,\n",
    "        batch_size  = batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    ave_time_cost = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for it, (images, labels, names) in enumerate(test_loader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            start_time = time.time()\n",
    "            logits = model(images)  # logits.size(): mini_batch*num_class*480*640\n",
    "            end_time = time.time()\n",
    "            if it>=5: # # ignore the first 5 frames\n",
    "                ave_time_cost += (end_time-start_time)\n",
    "            # convert tensor to numpy 1d array\n",
    "            label = labels.detach().cpu().numpy().squeeze().flatten()\n",
    "            prediction = logits.argmax(1).detach().cpu().numpy().squeeze().flatten() # prediction and label are both 1-d array, size: minibatch*640*480\n",
    "            # generate confusion matrix frame-by-frame\n",
    "            # conf = confusion_matrix(y_true=label, y_pred=prediction, labels=[0,1,2,3,4,5,6,7,8]) # conf is an n_class*n_class matrix, vertical axis: groundtruth, horizontal axis: prediction\n",
    "            # conf_total += conf\n",
    "            # save demo images\n",
    "            visualize(image_name=names, predictions=logits.argmax(1), weight_name=args.weight_name)\n",
    "            print(\"frame %d/%d, %s, time cost: %.2f ms, demo result saved.\"\n",
    "                  %(it+1, len(test_loader), names, (end_time-start_time)*1000))\n",
    "    print('Accomplished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pic = \"1500D\"\n",
    "# 指定图像路径（例如测试集中的第一张图像）\n",
    "image_path = 'runs/Predict_RTFNET_152_0{}.png'.format(pic)  # 根据实际路径调整\n",
    "image_path1 = 'runs/Pred_RTFNet_152_0{}.png'.format(pic)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "img = plt.imread(image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 隐藏坐标轴\n",
    "plt.title(\"Original\")\n",
    "plt.subplot(1, 2, 2)\n",
    "img1 = plt.imread(image_path1)\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')  # 隐藏坐标轴\n",
    "plt.title(\"Modified\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
